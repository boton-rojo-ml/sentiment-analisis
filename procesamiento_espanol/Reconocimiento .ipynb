{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconocimiento de comentarios negativos\n",
    "\n",
    "En esta libreta vamos a investiar si, utilizando métodos sencillos y \n",
    "librerías existentes podemos detectar los comentarios negativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Para el tratamiento del lenguaje\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Para el aprendizaje (se agregarán algunas más conforme se necesite)\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "import sklearn.metrics as metricas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 1: Recuperar y tratar los datos para usarse\n",
    "\n",
    "Los datos se encuentran en un directorio privado, los cuales ya se \n",
    "encuentran separados de un conjunto de prueba. \n",
    "\n",
    "Los datos se encuentran como una tabla tipo csv de la siguiente manera:\n",
    "\n",
    "Columnas  |    Nombre       |     Descripción\n",
    "----------|-----------------|----------------------------------------------------------\n",
    "1         |   S/N           |    numeración (sin sentido)\n",
    "2         |   id            |    Identificador del mensaje\n",
    "3         |   create_time   |    Fecha de creación del mensaje\n",
    "4         |   id_from       |    Identificador del usuario (emisor del mensaje)\n",
    "5         |   comment       |    El mensaje en si mismo\n",
    "6         |   like_count    |    Número de likes que recibió el mensaje\n",
    "7         |   flag          |    Polaridad (0 -> Negativo, 1 -> Positivo, 2 -> Neutro)\n",
    "8         |   ready         |    Revisado por un operador (1 -> No, 2 -> Si)\n",
    "\n",
    "Una vez recuperados los datos, se realiza el siguiente pretratamiento:\n",
    "\n",
    "1. La columna `flag` será el valor de salida y la columna `comment` \n",
    "   como variables de entrada, las cuales son string. \n",
    "   \n",
    "2. La columna `comment`la vamos a tratar, ya que cada usuario maneja \n",
    "   codificaciones diferentes y los datos están hechos un chile con queso.\n",
    "\n",
    "3. La columna `flag` se le asigna valor de 0 a los valores 1 y 2 \n",
    "   (comentarios no negativos) y valor de 1 a los que tienen valor de 0\n",
    "   (comentarios negativos). Convertimos el problema a un problema de\n",
    "   clasificación binaria.\n",
    "   \n",
    "4. Los datos se separan, 80% para entrenamiento y 20% para validación, \n",
    "   procurando que en ambos conjuntos haya la misma proporción de \n",
    "   elementos de ambas clases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cargamos los datos\n",
    "df = pd.read_csv(\"privado/data_train.csv\")\n",
    "\n",
    "X = df[\"comment\"]\n",
    "X = X.apply(lambda x: str(x).decode('unicode_escape').encode('utf-8', 'ignore').strip())\n",
    "\n",
    "y = np.array(df['flag'])\n",
    "\n",
    "# Problema binario 1 = Comentario negativo\n",
    "y = np.where(y > 0, 0, 1)\n",
    "\n",
    "# Separamos 20% para validación\n",
    "indices = StratifiedKFold(y, n_folds=5, shuffle=True, random_state=0)\n",
    "for tr_i, va_i in indices:\n",
    "    X_train, X_valid = X.loc[tr_i], X.loc[va_i]\n",
    "    y_train, y_valid = y[tr_i], y[va_i]\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 2: Genera la serie de operaciones a realizar.\n",
    "\n",
    "En esta paso vamos a decidir cuales métodos vamos a utilizar para tratar la información,\n",
    "y cual método vamos a utilizar para la clasificación. Los métodos que se seleccionen serán\n",
    "incluídos en un `pipeline` que nos ayuda a serializar las operaciones a realizar.\n",
    "\n",
    "Entre los métodos de vectorización de la información que podemos utilizar se encuentran:\n",
    "\n",
    "1. Bolsa de palabras (o bigramas): `CountVectorizer`\n",
    "2. Tf–idf term weighting: `TfidfVectorizer`\n",
    "\n",
    "Entre los métodos de reducción de la dimensionalidad se encuentran:\n",
    "\n",
    "1. Análisis en componentes principales para datos dispersos: `SparsePCA`\n",
    "2. Latent semantic analysis (LSA): `TruncatedSVD`\n",
    "\n",
    "Estos pueden ser utilizados en forma combinada. Los métodos de clasificación pueden ser:\n",
    "\n",
    "1. Máquina de Vectores de Soporte Lineal: `LinearSVC`\n",
    "2. Máquina de Vectores de Soporte: `SVC`\n",
    "3. Naive Bayes: `MultinomialNB`\n",
    "4. Bosques aleatorios: `RandomForestClassifier`\n",
    "5. AdaBoost: `AdaBoostClassifier`\n",
    "6. Árbol de desición: `DecisionTreeClassifier`\n",
    "\n",
    "Por último, es necesario decidir si hay parámetros que pueden ser modificados, y en que términos pueden ser modificados, esto se agrega en el diccionario `parameters`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "espanol_stopwords = stopwords.words('spanish')\n",
    "vectorizer = CountVectorizer(\n",
    "    analyzer='word',\n",
    "    lowercase=True,\n",
    "    stop_words=espanol_stopwords)\n",
    "\n",
    "# Pasos del procesamiento\n",
    "pipeline = Pipeline([\n",
    "     ('vect', vectorizer),\n",
    "     ('cls', LinearSVC()),\n",
    "    ])\n",
    "\n",
    "# Aqui definimos el espacio de parámetros a explorar\n",
    "parameters = {\n",
    "    # 'vect__max_df': (0.9, 0.95, 1.0),\n",
    "    # 'vect__min_df': (1, 0.05, 0.1),\n",
    "    'vect__max_features': (20000, 40000),\n",
    "    # 'vect__ngram_range': ((1, 1), (1, 2)),  # unigramas o bigramas\n",
    "    'cls__C': (0.001, 0.01, 0.1),\n",
    "    'cls__class_weight': ('balanced', None)\n",
    "    # 'cls__loss': ('hinge', 'squared_hinge'),\n",
    "    # 'cls__max_iter': (500, 1000)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 3. Ejecutar el script, buscando optimizar parámetros\n",
    "\n",
    "Hacemos el paso completo, pero vamos a checar todas las combinaciones de parámetros \n",
    "para seleccionar la que reduzca un criterio de error. Entre los criterios de error\n",
    "se encuentran `\"recall\"` y `\"f1\"` entre otros.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, scoring='recall')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Muestra los parametros seleccionados\n",
    "print grid_search.best_params_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 4: Analisis de los resultados\n",
    "\n",
    "Por último se observan los mejores resultados encontrados y analizamos que tan bien\n",
    "se desempeña en los datos de validación.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Muestra los resultados con datos de validacion\n",
    "y_est = grid_search.predict(X_valid)\n",
    "print metricas.confusion_matrix(y_valid, y_est)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
