{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconocimiento de comentarios negativos\n",
    "\n",
    "En esta libreta vamos a investiar si, utilizando métodos sencillos y \n",
    "librerías existentes podemos detectar los comentarios negativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Para el tratamiento del lenguaje\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Para el aprendizaje (se agregarán algunas más conforme se necesite)\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "import sklearn.metrics as metricas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 1: Recuperar y tratar los datos para usarse\n",
    "\n",
    "Los datos se encuentran en un directorio privado, los cuales ya se \n",
    "encuentran separados de un conjunto de prueba. \n",
    "\n",
    "Los datos se encuentran como una tabla tipo csv de la siguiente manera:\n",
    "\n",
    "Columnas  |    Nombre       |     Descripción\n",
    "----------|-----------------|----------------------------------------------------------\n",
    "1         |   id            |    Identificador del mensaje\n",
    "2         |   create_time   |    Fecha de creación del mensaje\n",
    "3         |   id_from       |    Identificador del usuario (emisor del mensaje)\n",
    "4         |   comment       |    El mensaje en si mismo\n",
    "5         |   like_count    |    Número de likes que recibió el mensaje\n",
    "6         |   flag          |    Polaridad (0 -> Negativo, 1 -> Positivo, 2 -> Neutro)\n",
    "7         |   ready         |    Revisado por un operador (1 -> No, 2 -> Si)\n",
    "\n",
    "Una vez recuperados los datos, se realiza el siguiente pretratamiento:\n",
    "\n",
    "1. La columna `flag` será el valor de salida y la columna `comment` \n",
    "   como variables de entrada, las cuales son string. \n",
    "   \n",
    "2. La columna `comment`la vamos a tratar, ya que cada usuario maneja \n",
    "   codificaciones diferentes y los datos están hechos un chile con queso.\n",
    "\n",
    "3. La columna `flag` se le asigna valor de 0 a los valores 1 y 2 \n",
    "   (comentarios no negativos) y valor de 1 a los que tienen valor de 0\n",
    "   (comentarios negativos). Convertimos el problema a un problema de\n",
    "   clasificación binaria.\n",
    "   \n",
    "4. Los datos se separan, 80% para entrenamiento y 20% para validación, \n",
    "   procurando que en ambos conjuntos haya la misma proporción de \n",
    "   elementos de ambas clases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cargamos los datos\n",
    "df = pd.read_csv(\"privado/data_train.csv\")\n",
    "\n",
    "X = df[\"comment\"]\n",
    "X = X.apply(lambda x: str(x).decode('unicode_escape').encode('utf-8', 'ignore').strip())\n",
    "\n",
    "y = np.array(df['flag'])\n",
    "\n",
    "# Problema binario 1 = Comentario negativo\n",
    "y = np.where(y > 0, 0, 1)\n",
    "\n",
    "# Separamos 20% para validación\n",
    "indices = StratifiedKFold(y, n_folds=5, shuffle=True, random_state=0)\n",
    "for tr_i, va_i in indices:\n",
    "    X_train, X_valid = X.loc[tr_i], X.loc[va_i]\n",
    "    y_train, y_valid = y[tr_i], y[va_i]\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 2: Genera la serie de operaciones a realizar.\n",
    "\n",
    "En esta paso vamos a decidir cuales métodos vamos a utilizar para tratar la información,\n",
    "y cual método vamos a utilizar para la clasificación. Los métodos que se seleccionen serán\n",
    "incluídos en un `pipeline` que nos ayuda a serializar las operaciones a realizar.\n",
    "\n",
    "Entre los métodos de vectorización de la información que podemos utilizar se encuentran:\n",
    "\n",
    "1. Bolsa de palabras (o bigramas): `CountVectorizer`\n",
    "2. Tf–idf term weighting: `TfidfVectorizer`\n",
    "\n",
    "Entre los métodos de reducción de la dimensionalidad se encuentran:\n",
    "\n",
    "1. Análisis en componentes principales para datos dispersos: `SparsePCA`\n",
    "2. Latent semantic analysis (LSA): `TruncatedSVD`\n",
    "\n",
    "Estos pueden ser utilizados en forma combinada. Los métodos de clasificación pueden ser:\n",
    "\n",
    "1. Máquina de Vectores de Soporte Lineal: `LinearSVC`\n",
    "2. Máquina de Vectores de Soporte: `SVC`\n",
    "3. Naive Bayes: `MultinomialNB`\n",
    "4. Bosques aleatorios: `RandomForestClassifier`\n",
    "5. AdaBoost: `AdaBoostClassifier`\n",
    "6. Árbol de desición: `DecisionTreeClassifier`\n",
    "\n",
    "Por último, es necesario decidir si hay parámetros que pueden ser modificados, y en que términos pueden ser modificados, esto se agrega en el diccionario `parameters`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "espanol_stopwords = stopwords.words('spanish')\n",
    "vectorizer = TfidfVectorizer(\n",
    "    analyzer='word',\n",
    "    lowercase=True,\n",
    "    stop_words=espanol_stopwords)\n",
    "\n",
    "reductor = TruncatedSVD(n_components=500)\n",
    "\n",
    "cls1 = LinearSVC(\n",
    "    C=0.05, \n",
    "    class_weight=\"balanced\", \n",
    "    max_iter = 10000)\n",
    "\n",
    "cls2 = AdaBoostClassifier(\n",
    "    n_estimators=100)\n",
    "\n",
    "cls3 = RandomForestClassifier(\n",
    "    n_estimators=500, \n",
    "    max_depth=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 3. Ejecutar el aprendizaje\n",
    "\n",
    "Hacemos el paso completo, pero vamos a checar todas las combinaciones de parámetros \n",
    "para seleccionar la que reduzca un criterio de error. Entre los criterios de error\n",
    "se encuentran `\"recall\"` y `\"f1\"` entre otros.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.05, class_weight='balanced', dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=10000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_vec = vectorizer.fit_transform(X_train)\n",
    "X_red = reductor.fit_transform(X_vec)\n",
    "cls1.fit(X_red, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 4: Analisis de los resultados\n",
    "\n",
    "Por último analizamos que tan bien se desempeña en los datos de validación.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9868 3057]\n",
      " [ 108 1119]]\n"
     ]
    }
   ],
   "source": [
    "# Muestra los resultados con datos de validacion\n",
    "X_vec = vectorizer.transform(X_valid)\n",
    "X_red = reductor.transform(X_vec)\n",
    "y_est = cls1.predict(X_red)\n",
    "\n",
    "print metricas.confusion_matrix(y_valid, y_est)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56605, 500)\n",
      "[[39714 11985]\n",
      " [  412  4494]]\n"
     ]
    }
   ],
   "source": [
    "# Muestra los resultados con datos de validacion\n",
    "X_vec = vectorizer.transform(X_train)\n",
    "X_red = reductor.transform(X_vec)\n",
    "y_est = cls1.predict(X_red)\n",
    "\n",
    "print X_red.shape\n",
    "print metricas.confusion_matrix(y_train, y_est)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
